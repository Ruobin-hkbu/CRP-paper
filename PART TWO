Part 2: Establishing Efficient Poetry Generator: Machine Learning’s Practice in AI Poetry 
                    
                We prove in theory that AI can be creative as human under the
condition that it can properly fit the data generated by human
creators.
                                                   —Wang et al.

   In the previous chapter, we’ve discussed humanities’ treatment on AI-generated texts. This chapter focus on poetry generation and human-AI collaboration in machine learning practice. 
The rise of machine learning and AI shifted emphasis towards algorithmic novelty and autonomous creativity, often valuing the generative process itself over the preservation of historical or literary context. Machine learning approaches seek to discover “intelligent” strategies for constructing poetry, typically focusing on computational methods and evaluating success by technical fluency or coherence rather than deep intertextual meaning. This divergence in priorities has led to a disconnect between the interpretive, context-sensitive impulses of the humanities and the process-oriented, experimental ethos of computer science (Linardaki, 2022). Therefore, how to bridge the gap between the two very different agendas remain crucial to this study.         
   We’ll start by exploring the evolution of computational poetry generation—from the rule-based systems to the sophisticated creativity enabled by Large Language Models (LLMs). Along this journey, differing objectives emerge: while the field of machine learning has largely focused on not generating poetry with human sentiments but on building ever more powerful natural language generation models, there has been a simultaneous, enduring effort on ensuring that poetry generation retains meaningful human engaged. This chapter investigates these parallel agendas, highlighting key initiatives and promising directions that seek to intertwine human creativity with machine intelligence. By examining notable attempts to infuse poetic generation systems with human sensibility and aspiration, the chapter aims to illuminate the evolving landscape of human–AI collaboration in machine learning practice. 

2.1 Brief history of machine learning models for poetry generation (explain the “how” to amatuers/  different agenda, different mission; why it is not satisficing enough?) 1666
    This section will mainly focus on academic projects in terms of developing poetry generators, from early rule-based systems to interactive models, from neural network to the rise of Large Language Models (LLMs). We’re going to explore the different approaches and trajectories of each models, their strengths and limitations, and the tendency of involving human engagement and seeking for human-AI collaboration/co-creation in the process. 
2.1.1 The development of poetry generation programs
Poetry generation has also been approached through rigorous scholarly initiatives. These academic projects have employed a range of techniques similar to those found in recreational poetry generators, but with greater transparency and methodological clarity. Notable examples include ASPERA (Gervás), TwitSong (Lamb et al.), PoeTryMe and Co-PoeTryMe (Oliveira et al.), Poevolve (Levy), Hafez (Ghazvininejad et al.)
ASPERA (Gervás), its full name Automatic Spanish Poetry Expert and Rewriting Application, is an example of early rule-based system that composes poetry in a semiautomatic and interactive fashion: it obtains from the user basic style parameters and intended image and selects the most appropriate metric structure for the user’s wishes. By emphasizing structural constraints such as meter and rhyme, it maintains fidelity to traditional poetic forms while automating the creative process.
PoeTryMe (Oliveira et al.) autonomously produces poems from a set of initial parameters, offers a rule-based framework generation, allowing users significant control over themes, vocabulary, and structure. It emphasizes the importance of customizable templates and lexicons, making the generation process transparent and adaptable. Its extension, Co-PoeTryMe, introduces interactive, collaborative elements, allowing humans to co-create with the system—reflecting a growing recognition of human-AI collaboration in the creative process. 
TwitSong (Lamb et al.) leverages social media data, combining statistical modeling with creative recombination. It extracts tweets and reassembles them into song lyrics or poems. TwitSong’s use of real-world, crowd-sourced language demonstrates a shift towards leveraging large, dynamic corpora and explores the creative potential of non-traditional text sources.
Poevolve (Levy) pioneers the application of evolutionary algorithms to poetry generation. Here, potential poems (encoded as individuals in a population) are iteratively evolved using mechanisms like selection, crossover, and mutation. Fitness functions gauge poetic qualities (form, rhyme, theme), gradually improving poem quality over generations.
Hafez (Ghazvininejad et al.) marks a transition from machine learning towards deep learning, employing recurrent neural networks to generate poetry, notably with constraints such as rhyme and meter. This model is data-driven, learning directly from large collections of poetry to produce outputs that are contextually relevant and stylistically consistent. Hafez demonstrates the power of neural approaches in modeling complex language patterns and paves the way for later, even more sophisticated models (such as LLMs). 
Trajectory Analysis: Across these systems, we observe a trajectory from rule-based and template-driven methodologies (ASPERA) to models that embrace data-driven and probabilistic methods (Poevolve) and ultimately to powerful neural architectures (Hafez). This progression mirrors broader trends in natural language processing—moving from explicit linguistic constraints and human defined and controlled rules to a more generalized, automatic, machine-learned models. However, we also observe yet another trend concerning the transparency, interactivity and real-world involvement, particularly as seen in PoeTryMe’s modular design and Co-PoeTryMe’s collaborative capabilities and TwitSong’s crowd-soured engagement. Such developments highlight the growing recognition and reinforcement of human agency within computational creativity. 
Deficiencies and limitations within each trajectories: While formal and surface-level aspects—such as rhyme, meter, and grammatical structure—can be modeled and reproduced, these programs struggle to replicate the subtleties, emotional resonance, and layered meanings intrinsic to human poetry. Rule-based methods (ASPERA, PoeTryMe) are limited by the expressive scope of their templates, while even advanced neural models (Hafez) often default to accessible clichés or shallow interpretations, missing the intentional ambiguity, intertextuality, and profound symbolic play that characterize accomplished human verse. 
Interactive extensions (e.g., Co-PoeTryMe) and preference-based learning have enabled some degree of human-machine synergy. However, these systems genuinely evolve in response to ongoing, open-ended human engagement. Their adaptation is confined to predefined interaction loops (user selects, system updates), rather than true collaborative growth where both the system and its creative direction evolve perpetually and dynamically. The dynamics of dialogic, iterative, and contextually aware exchange—core to human artistic collaboration—remain beyond current computational reach.
2.1.2 Rise of Large Language Models (LLM) 
   The advent of Large Language Models (LLMs) such as GPTs and BERT has ushered in a new era for artificial intelligence in the field of literary creativity. LLMs exhibit a remarkable ability to understand, generate, and manipulate natural language in ways previously unimaginable. Among the most intriguing applications of these models is poetry generation, where the technical prowess of LLM intersects with the nuanced, expressive realm of human literary art. This section will focus on how LLMs operate, why they are game changer for poetry generation, their application and outputs on poetic corpus, and finally, the limitations of LLM-generated poetry.
How LLMs Operate: The core principle behind LLMs is learning to predict and generate human-like text by modeling the statistical relationships between words and phrases across vast amounts of text data. In 2017, a foundational academic article “Attention Is All You Need” (Vaswani et al.) introduces a new transformer architecture that replaces recurrent neural networks (RNNs) and convolutional neural networks (CNNs) with a mechanism called self-attention. Self-attention enables the model to weigh the significance of each word in a sequence relative to the others when producing an encoding for each word. For each word (“token”), the model generates three vectors—Query (Q), Key (K), and Value (V)—and compares the Query to all Keys in the sequence: 1) The similarity of the Query to each Key produces attention weights. 2) These weights are then used to form a weighted sum of the Values, giving each word an encoding that considers the context of the whole sequence.  
In practice, given an input prompt, LLMs generate text one token at a time by selecting the most likely continuation, sampling from the probability distribution the model assigns to possible next words or tokens. At the time of generation, the model takes a prompt (initial sequence), then selects the next most probable word, appends it to the sequence, and repeats this process to produce coherent, contextually appropriate text. (Radford et al., 2019). 
LLM, creative writing and poetry generation: 
   Large Language Models (LLMs) such as GPT-2, GPT-3, and GPT-4 have revolutionized the field of automatic text generation, exerting profound impact on creative domains like poetry and story writing. .Compared to traditional poetry generators, LLMs are unbound by any rule-based or template-based system, ensuring their ability to adapt to any theme, tone, or vocabulary based on the given prompt, They can also generate contextually rich and stylistically diverse language artifacts (Brown et al., 2020). 
Practical application of LLMs in creative writing and poetry writing suggests fruitful outcomes. For example, LLMs are used to assist writers by generating ideas, completing lines, or offering stylistic suggestions, thus serving as co-creators in the writing process (Clark et al., 2018); In terms of poetry generation, they can be applied within a context-aware, sequence-to-sequence framework, significantly enhancing the coherence and connection among lines (Gao et al. 2021); Hu et al. (2022) introduced CharPoet, a token-free LLM architecture for Chinese classical poetry, enabling precise control over both content and format. CharPoet outperformed traditional token-based models in format fidelity, demonstrating LLMs’ capacity to generate poetry with nuanced structural requirements and tailored content; Another LLM program PoetryDiffusion achieves a comprehensive semantic understanding and incorporating a flexible metrical constraint module, significantly outperforms existing models in both automatic and human evaluations, marking a notable advance in controllable poetry generation methods (Hu et al. 2024).
Limitations and Challenges: 
Despite the remarkable advancements that LLMs have brought to automatic poetry and creative text generation, their outputs still face notable challenges.
Clark et al. (2018) suggests that even though participants found the AI creative writing process fun and helpful, machine suggestions do not necessarily lead to better written artifacts, indicating that human discernment remains crucial. Hitsuwari et al. (2024) demonstrates that LLM-generated haiku without human input were rated on par with those crafted by humans, suggesting that poems generated by LLMs still lack the depth of human poetry. Poetry is much more complicated an artifact than calculating semantic probabilities. 
Another challenge is that, absent thoughtful prompts or human constraints, LLMs tend to default to generating content that is generic, formulaic, or overly reliant on common patterns found in their training data (Zhou and Lee, 2024). This “regression to the mean” effect might risk the poetry being repetitive, predictable, or lacking in distinctive voice and creativity. Such genericity can be exacerbated by either uninspired user prompts or insufficiently curated training data. This is especially problematic for creative tasks like poetry, where originality and a unique voice are highly valued.
2.2 Human-AI collaboration in practice: Supporting creative poetry writing and poetics appreciation through AI 
     In respond to 2.1 of calling for more human engagement in machine learning practice, this section will focus on the establishment of a Human-AI Co-creation Model: its significance, its application and previous examples, and possible future development. 
     Evidence from recent research (Mahmud, Hong and Fong, 2023 ) demonstrates that human–AI symbiosis, enabled by deep learning advances, not only enhances efficiency and problem-solving capabilities but also improves human satisfaction and outcomes. As deep learning technologies continue to evolve, facilitating more seamless cooperation, human–AI teaming stands out as a key avenue for maximizing societal benefit and driving innovation across diverse domains. An analysis (Wu et al.) of over 1,600 application cases reveals that human–AI co-creation expands the potential for meaning-making, enhances efficiency, and makes creative work more accessible and inclusive. The Human-AI Co-Creation Model further illustrates how this collaboration transforms each stage of creativity.
     In terms of artistic creation, Zou and Lee’s study (2024) demonstrates that generative AI tools substantially boost human creative productivity and increase the value of digital artworks within creative communities. Although overall content novelty becomes more diffuse even as new creative frontiers are explored, and stylistic visual novelty diminishes, artists who leverage AI for more novel ideation are rewarded with greater peer recognition. Furthermore, the decreased concentration of value among adopters points to a more democratized creative landscape. These findings underscore the evolving dynamics of creativity in the age of AI and highlight the emergence of “generative synesthesia,” where mastering both ideation and filtering becomes essential for maximizing the collective creative potential of human–AI collaboration. Hitsuwari et al. (2023) conclude that haiku produced through human–AI collaboration achieved the highest aesthetic evaluations, surpassing both human-only and fully autonomous AI outputs. Moreover, the observed negative correlation between identification accuracy and perceived beauty highlights a tendency to attribute higher-quality poetry to human authorship, revealing a persistent algorithm aversion. The study emphasizes both the creative advantages of human–AI partnerships in literary arts and the potential for misattribution and undervaluation of AI-generated works, offering new insights into how collaboration may shape the future of creative expression. 
        In summary, a human-AI co-creation mode has at least the following advantages: 
1)Enhanced Efficiency and Problem-Solving: Human–AI symbiosis, particularly through advances in deep learning, streamlines workflows, increases productivity, and improves outcomes by combining the strengths of both humans and machines (Mahmud, Hong, & Fong, 2023)
2)Increased Creativity and Value in Artistic Domains: Collaboration with AI tools significantly boosts creative productivity, generates higher-value artworks, and allows artists to explore more diverse and novel ideas, which are often rewarded with greater peer recognition (Zou & Lee, 2024).
3)Greater Accessibility and Inclusivity in Creative Work: Human–AI co-creation expands opportunities for creative participation, making creative processes more accessible and inclusive to a wider range of individuals, and democratizes success by decreasing value concentration among elite adopters (Wu et al.; Zou & Lee, 2024)
4)Superior Quality and Aesthetic Outcomes: Human–AI collaborative outputs, such as poetry or haiku, not only achieve the highest aesthetic evaluations compared to solely human or solely AI-generated works but also challenge conventional perceptions of authorship and creativity, prompting the transformation of traditional poetry writing methods, norms and concepts. (Hitsuwari et al., 2023)

These advantages highlight the transformative potential of human–AI collaboration in enhancing efficiency, creativity, inclusivity, and quality across domains.

2.3.1 Previous examples of Human-AI co-creation in creative writing 
 Recently, various projects and experiments have demonstrated how AI systems—particularly those leveraging large language models—can work alongside human authors to generate compelling narratives, spurring new forms of artistic expression. From AI-assisted poetry composition to the collaborative drafting of short stories and scripts, these examples highlight both the creative possibilities and unique challenges of human-AI co-creation. By examining notable case studies and their methodologies, we can better understand how this partnership is implemented in practice. 
    Case studies:
   PÉrez Ý PÉrez and Sharples (2010)  implemented a engagement-reflection cognitive model in supporting creative writing with a machine. The system operates in two alternating phases: engagement and reflection. During the engagement phase, the program incrementally generates new story content by exploring a network of pre-defined story actions and characters, using content and rhetorical constraints but without reliance on explicit goals, plot structures, or templates. This simulates a writer’s free-flowing, associative thinking. In the reflection phase, the system halts content generation to evaluate the evolving narrative. It applies a set of criteria to resolve creative impasses, assess the novelty and interest of the narrative, and ensure overall coherence and logical consistency. If issues are detected, the program may revise or expand the narrative before resuming content generation. The system was evaluated by generating multiple story drafts and subjecting them to both automated and human assessment, focusing on qualities such as coherence, novelty, and reader engagement. 
Another example is provided by Clark et al.(2018), which centers on a “human-machine in-the-loop” framework, where human writers and AI models iteratively collaborate in the creative writing process. The research conducted case studies in two domains—slogan creation and short story writing—using language models to generate suggestions based on human input. Writers alternated between providing prompts and receiving machine-generated outputs, which they could accept, modify, or reject. The effectiveness of this collaboration was evaluated both quantitatively (by measuring creativity, diversity, and relevance of outputs) and qualitatively (through participant feedback and analysis of writing outcomes). This methodology highlights how integrating AI into cyclic human-machine interactions can support and inspire creative work, while still relying on human judgment and editorial control at each stage.
In comparison, Chang and Li (2025) propose a framework for collaborating a large language model in triggering creative ideas, which involves the designing and implementing the GPS (Goals, Prompts, Strategies) to guide human-AI collaboration during brainstorming sessions. Through design examples and real-world case studies, the methodology demonstrated that systematically collaborating with an LLM tool—by setting clear goals and iteratively refining prompts—can effectively stimulate creative ideation and enhance the overall creative output of brainstorming practices.
The GPS methodology includes: the goal is determined through a thorough analysis of the needs for exploration, driving the designer’s thinking direction. This decision results in two distinct phases: divergence and convergence. If the goal is to expand the thinking solution space or discover more creative possible options, the divergence phase should be selected. Otherwise, if the aim is to find more accurate answers from existing outcomes, the convergence phase should be chosen; Then, designers were provided with structured prompts and strategies aligned with specific creative goals while interacting with a large language model (LLM) tool, such as ChatGPT. The effectiveness of the framework was evaluated using established creativity metrics from the Torrance Tests of Creative Thinking, including fluency, flexibility, originality, and elaboration.  

Key Differences :
Degree of Human Involvement:

 PÉrez Ý PÉrez and Sharples largely automates creation, with periodic external human evaluation;
Clark et al. and Chang & Li both place humans in the creative loop, but differ in structure (open-ended alternation vs. structured GPS phases).

Interaction Structure:

  PÉrez Ý PÉrez and Sharples: System-driven, based on internal cognitive cycle;
Clark et al.: Dynamic, open-ended human–AI turn-taking;
Chang and Li: Highly structured, goal- and strategy-driven human-AI dialogue.

  Evaluation Metrics:

PÉrez Ý PÉrez and Sharples: Qualitative and human review;
Clark et al.: Combination of quantitative and qualitative;
Chang and Li: Standardized creativity testing.

Limitation Analysis: 
The three studies on human-AI collaborative creativity differ notably in methodology and present distinct limitations. Pérez y Pérez and Sharples (2010) implemented a automated story generation through alternating engagement and reflection phases in which a computational model generates and periodically evaluates story material. Human involvement is primarily limited to post-hoc evaluation of output, and the story world is constrained by pre-defined actions and rules. This results in limited adaptability and domain transferability, and the absence of interactive human input during creation may reduce the relatability and spontaneity of the narratives produced.
In contrast, Clark et al. (2018) employ a human-in-the-loop approach, where creative writing unfolds through iterative, back-and-forth exchanges: the AI suggests content in response to human prompts, while writers retain editorial control, selecting or rejecting machine proposals. Though more dynamic and participatory, their method’s effectiveness is still tied to the capabilities of the AI models available at the time, and achieving strong, coherent long-form narratives remains challenging. Moreover, unstructured exchanges may require substantial human effort to shepherd the process toward high-quality results.
Chang and Li (2025) introduce a structured collaboration framework—the GPS model—that leverages large language models as ideation partners in both divergent and convergent phases of brainstorming. By explicitly setting goals, crafting prompts, and employing targeted strategies, this model offers systematic support for stimulating creative ideas and is evaluated with established creativity metrics. However, this method’s rigidity may limit the emergence of unexpected insights, and its success depends on a user’s ability to articulate and adapt prompts and goals effectively; it has not been broadly tested across all creative domains.

2.3.2 The idea of establishing a customized chatbot with a dynamic in-a-loop system: Enabling users to move from functional writing to creative writing via AI collaboration
   
   Based on the analysis of three different human-AI collaboration mechanism mentioned in 2.3.1, this study introduces a combination of a structured, goal- and strategy-driven human-AI dialogue with an interactive and dynamic human involvement—a customized Chatbot with a dynamic human-machine in-a-loop system—specifically designed to guide users from functionally assembling poems to engaging in truly creative poetry writing By fostering an interactive environment where users actively participate in iterative co-creation with the AI.
A customized chatbot is an artificial intelligence-driven conversational agent that has been deliberately tailored to accommodate specific user needs, preferences, or particular domains of knowledge, often through configuration of its dialogue style, content scope, functionality, or even visual appearance (Shum et al., 2018; Ashktorab et al., 2019). 
Wald, Heyselaar, and Bosse (2021) investigates customization in a general context, defining it as active user-driven adaptation of chatbot features or behavior to enhance trust and user experience. Davies et al. (2021) frame a customized chatbot as an AI tool that constructs personalized learning paths and consultative guidance in e-Learning, while Arun et al. (2024) details the creation a domain-specific chatbot rigorously trained on a curated anatomy knowledge base to optimize factual accuracy and relevance. The consensus across these studies is that customization could significantly improve human-AI collaboration. Personalization empowers users—by adapting conversation style (Wald, Heyselaar, and Bosse ), content (Davies et al. ), or information delivery to precise standards (Arun et al. )—thus fostering greater engagement, trust, and potentially more effective outcomes than generic, one-size-fits-all agents. Customization better addresses individual differences, supplies timely, relevant support, and may increase both user satisfaction and trust in the technology.
   Despite these advantages, customized chatbot in previous studies also reveal areas still needing development: 1) the main challenge lies in designing the underlying behavior, analytic algorithms, and content curation to ensure meaningful and contextualized personalization; 2) the importance of accurate, domain-specific knowledge and points to ongoing challenges in user acceptance, evidence of learning improvement, and the continual need to address AI limitations such as bias or hallucinated responses. 
To address these ongoing challenges and maximize the benefits of chatbot customization, it is crucial to establish a robust human-machine in-a-loop system (see also 1.3.2). Such a system does not rely solely on static personalization algorithms or predefined responses; instead, it empowers users to iteratively shape and refine the chatbot’s behavior, content, and creative output throughout the interaction process. By embedding dynamic user feedback, co-creative decision-making, and real-time adaptability at the core of the chatbot’s functioning, we ensure that the AI remains sensitive to evolving user goals, preferences, and contextual nuances—particularly important in domains like creative poetry writing where inspiration and intent can shift rapidly. A human-machine in-a-loop approach transforms the chatbot from a mere tool into a genuine collaborative partner, capable of growing alongside the user and overcoming the limitations of generic or rigidly programmed agents. This iterative, participatory loop is thus essential for achieving deeper personalization, fostering continuous improvement, and building greater trust and engagement in the human-AI creative collaboration. 

2.3 How to effectively establish a human-AI co-creation mode in poetry writing: Integration of humanity insights into ML practice
2.3.1 Attempts to model meaningfulness and aesthetic value with human feedback loops— “adding layers” into the system. 
2.3.2 Why not machine evaluators? Ethics concerns and limitations of algorithmic evaluation.
